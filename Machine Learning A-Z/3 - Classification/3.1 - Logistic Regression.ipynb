{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to model binary variates\n",
    "# To predict 0/1 behavior, we can use probabilities\n",
    "# Given linear equation of the from y = b_0 + b_1*x\n",
    "# Apply sigmoid function p = 1/(1 + e^(-y))\n",
    "# We obtain ln(p/(1 - p)) = y = b_0 + b_1*x\n",
    "# This provides us with a logistic plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Social_Network_Ads.csv\")\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  EstimatedSalary  Purchased\n",
       "0   19            19000          0\n",
       "1   35            20000          0\n",
       "2   26            43000          0\n",
       "3   27            57000          0\n",
       "4   19            76000          0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    44  39000]\n",
      " [    32 120000]\n",
      " [    38  50000]\n",
      " [    32 135000]\n",
      " [    52  21000]\n",
      " [    53 104000]\n",
      " [    39  42000]\n",
      " [    38  61000]\n",
      " [    36  50000]\n",
      " [    36  63000]\n",
      " [    35  25000]\n",
      " [    35  50000]\n",
      " [    42  73000]\n",
      " [    47  49000]\n",
      " [    59  29000]\n",
      " [    49  65000]\n",
      " [    45 131000]\n",
      " [    31  89000]\n",
      " [    46  82000]\n",
      " [    47  51000]\n",
      " [    26  15000]\n",
      " [    60 102000]\n",
      " [    38 112000]\n",
      " [    40 107000]\n",
      " [    42  53000]\n",
      " [    35  59000]\n",
      " [    48  41000]\n",
      " [    48 134000]\n",
      " [    38 113000]\n",
      " [    29 148000]\n",
      " [    26  15000]\n",
      " [    60  42000]\n",
      " [    24  19000]\n",
      " [    42 149000]\n",
      " [    46  96000]\n",
      " [    28  59000]\n",
      " [    39  96000]\n",
      " [    28  89000]\n",
      " [    41  72000]\n",
      " [    45  26000]\n",
      " [    33  69000]\n",
      " [    20  82000]\n",
      " [    31  74000]\n",
      " [    42  80000]\n",
      " [    35  72000]\n",
      " [    33 149000]\n",
      " [    40  71000]\n",
      " [    51 146000]\n",
      " [    46  79000]\n",
      " [    35  75000]\n",
      " [    38  51000]\n",
      " [    36  75000]\n",
      " [    37  78000]\n",
      " [    38  61000]\n",
      " [    60 108000]\n",
      " [    20  82000]\n",
      " [    57  74000]\n",
      " [    42  65000]\n",
      " [    26  80000]\n",
      " [    46 117000]\n",
      " [    35  61000]\n",
      " [    21  68000]\n",
      " [    28  44000]\n",
      " [    41  87000]\n",
      " [    37  33000]\n",
      " [    27  90000]\n",
      " [    39  42000]\n",
      " [    28 123000]\n",
      " [    31 118000]\n",
      " [    25  87000]\n",
      " [    35  71000]\n",
      " [    37  70000]\n",
      " [    35  39000]\n",
      " [    47  23000]\n",
      " [    35 147000]\n",
      " [    48 138000]\n",
      " [    26  86000]\n",
      " [    25  79000]\n",
      " [    52 138000]\n",
      " [    51  23000]\n",
      " [    35  60000]\n",
      " [    33 113000]\n",
      " [    30 107000]\n",
      " [    48  33000]\n",
      " [    41  80000]\n",
      " [    48  96000]\n",
      " [    31  18000]\n",
      " [    31  71000]\n",
      " [    43 129000]\n",
      " [    59  76000]\n",
      " [    18  44000]\n",
      " [    36 118000]\n",
      " [    42  90000]\n",
      " [    47  30000]\n",
      " [    26  43000]\n",
      " [    40  78000]\n",
      " [    46  59000]\n",
      " [    59  42000]\n",
      " [    46  74000]\n",
      " [    35  91000]\n",
      " [    28  59000]\n",
      " [    40  57000]\n",
      " [    59 143000]\n",
      " [    57  26000]\n",
      " [    52  38000]\n",
      " [    47 113000]\n",
      " [    53 143000]\n",
      " [    35  27000]\n",
      " [    58 101000]\n",
      " [    45  45000]\n",
      " [    23  82000]\n",
      " [    46  23000]\n",
      " [    42  65000]\n",
      " [    28  84000]\n",
      " [    38  59000]\n",
      " [    26  84000]\n",
      " [    29  28000]\n",
      " [    37  71000]\n",
      " [    22  55000]\n",
      " [    48  35000]\n",
      " [    49  28000]\n",
      " [    38  65000]\n",
      " [    27  17000]\n",
      " [    46  28000]\n",
      " [    48 141000]\n",
      " [    26  17000]\n",
      " [    35  97000]\n",
      " [    39  59000]\n",
      " [    24  27000]\n",
      " [    32  18000]\n",
      " [    46  88000]\n",
      " [    35  58000]\n",
      " [    56  60000]\n",
      " [    47  34000]\n",
      " [    40  72000]\n",
      " [    32 100000]\n",
      " [    19  21000]\n",
      " [    25  90000]\n",
      " [    35  88000]\n",
      " [    28  32000]\n",
      " [    50  20000]\n",
      " [    40  59000]\n",
      " [    50  44000]\n",
      " [    35  72000]\n",
      " [    40 142000]\n",
      " [    46  32000]\n",
      " [    39  71000]\n",
      " [    20  74000]\n",
      " [    29  75000]\n",
      " [    31  76000]\n",
      " [    47  25000]\n",
      " [    40  61000]\n",
      " [    34 112000]\n",
      " [    38  80000]\n",
      " [    42  75000]\n",
      " [    47  47000]\n",
      " [    39  75000]\n",
      " [    19  25000]\n",
      " [    37  80000]\n",
      " [    36  60000]\n",
      " [    41  52000]\n",
      " [    36 125000]\n",
      " [    48  29000]\n",
      " [    36 126000]\n",
      " [    51 134000]\n",
      " [    27  57000]\n",
      " [    38  71000]\n",
      " [    39  61000]\n",
      " [    22  27000]\n",
      " [    33  60000]\n",
      " [    48  74000]\n",
      " [    58  23000]\n",
      " [    53  72000]\n",
      " [    32 117000]\n",
      " [    54  70000]\n",
      " [    30  80000]\n",
      " [    58  95000]\n",
      " [    26  52000]\n",
      " [    45  79000]\n",
      " [    24  55000]\n",
      " [    40  75000]\n",
      " [    33  28000]\n",
      " [    44 139000]\n",
      " [    22  18000]\n",
      " [    33  51000]\n",
      " [    43 133000]\n",
      " [    24  32000]\n",
      " [    46  22000]\n",
      " [    35  55000]\n",
      " [    54 104000]\n",
      " [    48 119000]\n",
      " [    35  53000]\n",
      " [    37 144000]\n",
      " [    23  66000]\n",
      " [    37 137000]\n",
      " [    31  58000]\n",
      " [    33  41000]\n",
      " [    45  22000]\n",
      " [    30  15000]\n",
      " [    19  19000]\n",
      " [    49  74000]\n",
      " [    39 122000]\n",
      " [    35  73000]\n",
      " [    39  71000]\n",
      " [    24  23000]\n",
      " [    41  72000]\n",
      " [    29  83000]\n",
      " [    54  26000]\n",
      " [    35  44000]\n",
      " [    37  75000]\n",
      " [    29  47000]\n",
      " [    31  68000]\n",
      " [    42  54000]\n",
      " [    30 135000]\n",
      " [    52 114000]\n",
      " [    50  36000]\n",
      " [    56 133000]\n",
      " [    29  61000]\n",
      " [    30  89000]\n",
      " [    26  16000]\n",
      " [    33  31000]\n",
      " [    41  72000]\n",
      " [    36  33000]\n",
      " [    55 125000]\n",
      " [    48 131000]\n",
      " [    41  71000]\n",
      " [    30  62000]\n",
      " [    37  72000]\n",
      " [    41  63000]\n",
      " [    58  47000]\n",
      " [    30 116000]\n",
      " [    20  49000]\n",
      " [    37  74000]\n",
      " [    41  59000]\n",
      " [    49  89000]\n",
      " [    28  79000]\n",
      " [    53  82000]\n",
      " [    40  57000]\n",
      " [    60  34000]\n",
      " [    35 108000]\n",
      " [    21  72000]\n",
      " [    38  71000]\n",
      " [    39 106000]\n",
      " [    37  57000]\n",
      " [    26  72000]\n",
      " [    35  23000]\n",
      " [    54 108000]\n",
      " [    30  17000]\n",
      " [    39 134000]\n",
      " [    29  43000]\n",
      " [    33  43000]\n",
      " [    35  38000]\n",
      " [    41  45000]\n",
      " [    41  72000]\n",
      " [    39 134000]\n",
      " [    27 137000]\n",
      " [    21  16000]\n",
      " [    26  32000]\n",
      " [    31  66000]\n",
      " [    39  73000]\n",
      " [    41  79000]\n",
      " [    47  50000]\n",
      " [    41  30000]\n",
      " [    37  93000]\n",
      " [    60  46000]\n",
      " [    25  22000]\n",
      " [    28  37000]\n",
      " [    38  55000]\n",
      " [    36  54000]\n",
      " [    20  36000]\n",
      " [    56 104000]\n",
      " [    40  57000]\n",
      " [    42 108000]\n",
      " [    20  23000]\n",
      " [    40  65000]\n",
      " [    47  20000]\n",
      " [    18  86000]\n",
      " [    35  79000]\n",
      " [    57  33000]\n",
      " [    34  72000]\n",
      " [    49  39000]\n",
      " [    27  31000]\n",
      " [    19  70000]\n",
      " [    39  79000]\n",
      " [    26  81000]\n",
      " [    25  80000]\n",
      " [    28  85000]\n",
      " [    55  39000]\n",
      " [    50  88000]\n",
      " [    49  88000]\n",
      " [    52 150000]\n",
      " [    35  65000]\n",
      " [    42  54000]\n",
      " [    34  43000]\n",
      " [    37  52000]\n",
      " [    48  30000]\n",
      " [    29  43000]\n",
      " [    36  52000]\n",
      " [    27  54000]\n",
      " [    26 118000]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1\n",
      " 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0\n",
      " 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1\n",
      " 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    30  87000]\n",
      " [    38  50000]\n",
      " [    35  75000]\n",
      " [    30  79000]\n",
      " [    35  50000]\n",
      " [    27  20000]\n",
      " [    31  15000]\n",
      " [    36 144000]\n",
      " [    18  68000]\n",
      " [    47  43000]\n",
      " [    30  49000]\n",
      " [    28  55000]\n",
      " [    37  55000]\n",
      " [    39  77000]\n",
      " [    20  86000]\n",
      " [    32 117000]\n",
      " [    37  77000]\n",
      " [    19  85000]\n",
      " [    55 130000]\n",
      " [    35  22000]\n",
      " [    35  47000]\n",
      " [    47 144000]\n",
      " [    41  51000]\n",
      " [    47 105000]\n",
      " [    23  28000]\n",
      " [    49 141000]\n",
      " [    28  87000]\n",
      " [    29  80000]\n",
      " [    37  62000]\n",
      " [    32  86000]\n",
      " [    21  88000]\n",
      " [    37  79000]\n",
      " [    57  60000]\n",
      " [    37  53000]\n",
      " [    24  58000]\n",
      " [    18  52000]\n",
      " [    22  81000]\n",
      " [    34  43000]\n",
      " [    31  34000]\n",
      " [    49  36000]\n",
      " [    27  88000]\n",
      " [    41  52000]\n",
      " [    27  84000]\n",
      " [    35  20000]\n",
      " [    43 112000]\n",
      " [    27  58000]\n",
      " [    37  80000]\n",
      " [    52  90000]\n",
      " [    26  30000]\n",
      " [    49  86000]\n",
      " [    57 122000]\n",
      " [    34  25000]\n",
      " [    35  57000]\n",
      " [    34 115000]\n",
      " [    59  88000]\n",
      " [    45  32000]\n",
      " [    29  83000]\n",
      " [    26  80000]\n",
      " [    49  28000]\n",
      " [    23  20000]\n",
      " [    32  18000]\n",
      " [    60  42000]\n",
      " [    19  76000]\n",
      " [    36  99000]\n",
      " [    19  26000]\n",
      " [    60  83000]\n",
      " [    24  89000]\n",
      " [    27  58000]\n",
      " [    40  47000]\n",
      " [    42  70000]\n",
      " [    32 150000]\n",
      " [    35  77000]\n",
      " [    22  63000]\n",
      " [    45  22000]\n",
      " [    27  89000]\n",
      " [    18  82000]\n",
      " [    42  79000]\n",
      " [    40  60000]\n",
      " [    53  34000]\n",
      " [    47 107000]\n",
      " [    58 144000]\n",
      " [    59  83000]\n",
      " [    24  55000]\n",
      " [    26  35000]\n",
      " [    58  38000]\n",
      " [    42  80000]\n",
      " [    40  75000]\n",
      " [    59 130000]\n",
      " [    46  41000]\n",
      " [    41  60000]\n",
      " [    42  64000]\n",
      " [    37 146000]\n",
      " [    23  48000]\n",
      " [    25  33000]\n",
      " [    24  84000]\n",
      " [    27  96000]\n",
      " [    23  63000]\n",
      " [    48  33000]\n",
      " [    48  90000]\n",
      " [    42 104000]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.58 -0.89]\n",
      " [-0.61  1.46]\n",
      " [-0.01 -0.57]\n",
      " [-0.61  1.9 ]\n",
      " [ 1.37 -1.41]\n",
      " [ 1.47  1.  ]\n",
      " [ 0.09 -0.8 ]\n",
      " [-0.01 -0.25]\n",
      " [-0.21 -0.57]\n",
      " [-0.21 -0.19]\n",
      " [-0.31 -1.29]\n",
      " [-0.31 -0.57]\n",
      " [ 0.38  0.1 ]\n",
      " [ 0.88 -0.6 ]\n",
      " [ 2.07 -1.18]\n",
      " [ 1.08 -0.13]\n",
      " [ 0.68  1.78]\n",
      " [-0.71  0.56]\n",
      " [ 0.78  0.36]\n",
      " [ 0.88 -0.54]\n",
      " [-1.2  -1.58]\n",
      " [ 2.17  0.94]\n",
      " [-0.01  1.23]\n",
      " [ 0.19  1.08]\n",
      " [ 0.38 -0.48]\n",
      " [-0.31 -0.31]\n",
      " [ 0.98 -0.83]\n",
      " [ 0.98  1.87]\n",
      " [-0.01  1.26]\n",
      " [-0.9   2.27]\n",
      " [-1.2  -1.58]\n",
      " [ 2.17 -0.8 ]\n",
      " [-1.4  -1.47]\n",
      " [ 0.38  2.3 ]\n",
      " [ 0.78  0.77]\n",
      " [-1.   -0.31]\n",
      " [ 0.09  0.77]\n",
      " [-1.    0.56]\n",
      " [ 0.28  0.07]\n",
      " [ 0.68 -1.26]\n",
      " [-0.51 -0.02]\n",
      " [-1.8   0.36]\n",
      " [-0.71  0.13]\n",
      " [ 0.38  0.3 ]\n",
      " [-0.31  0.07]\n",
      " [-0.51  2.3 ]\n",
      " [ 0.19  0.04]\n",
      " [ 1.27  2.22]\n",
      " [ 0.78  0.27]\n",
      " [-0.31  0.16]\n",
      " [-0.01 -0.54]\n",
      " [-0.21  0.16]\n",
      " [-0.11  0.24]\n",
      " [-0.01 -0.25]\n",
      " [ 2.17  1.11]\n",
      " [-1.8   0.36]\n",
      " [ 1.87  0.13]\n",
      " [ 0.38 -0.13]\n",
      " [-1.2   0.3 ]\n",
      " [ 0.78  1.37]\n",
      " [-0.31 -0.25]\n",
      " [-1.7  -0.05]\n",
      " [-1.   -0.74]\n",
      " [ 0.28  0.5 ]\n",
      " [-0.11 -1.06]\n",
      " [-1.1   0.59]\n",
      " [ 0.09 -0.8 ]\n",
      " [-1.    1.55]\n",
      " [-0.71  1.4 ]\n",
      " [-1.3   0.5 ]\n",
      " [-0.31  0.04]\n",
      " [-0.11  0.01]\n",
      " [-0.31 -0.89]\n",
      " [ 0.88 -1.35]\n",
      " [-0.31  2.24]\n",
      " [ 0.98  1.98]\n",
      " [-1.2   0.48]\n",
      " [-1.3   0.27]\n",
      " [ 1.37  1.98]\n",
      " [ 1.27 -1.35]\n",
      " [-0.31 -0.28]\n",
      " [-0.51  1.26]\n",
      " [-0.8   1.08]\n",
      " [ 0.98 -1.06]\n",
      " [ 0.28  0.3 ]\n",
      " [ 0.98  0.77]\n",
      " [-0.71 -1.5 ]\n",
      " [-0.71  0.04]\n",
      " [ 0.48  1.72]\n",
      " [ 2.07  0.19]\n",
      " [-1.99 -0.74]\n",
      " [-0.21  1.4 ]\n",
      " [ 0.38  0.59]\n",
      " [ 0.88 -1.15]\n",
      " [-1.2  -0.77]\n",
      " [ 0.19  0.24]\n",
      " [ 0.78 -0.31]\n",
      " [ 2.07 -0.8 ]\n",
      " [ 0.78  0.13]\n",
      " [-0.31  0.62]\n",
      " [-1.   -0.31]\n",
      " [ 0.19 -0.36]\n",
      " [ 2.07  2.13]\n",
      " [ 1.87 -1.26]\n",
      " [ 1.37 -0.92]\n",
      " [ 0.88  1.26]\n",
      " [ 1.47  2.13]\n",
      " [-0.31 -1.23]\n",
      " [ 1.97  0.91]\n",
      " [ 0.68 -0.71]\n",
      " [-1.5   0.36]\n",
      " [ 0.78 -1.35]\n",
      " [ 0.38 -0.13]\n",
      " [-1.    0.42]\n",
      " [-0.01 -0.31]\n",
      " [-1.2   0.42]\n",
      " [-0.9  -1.21]\n",
      " [-0.11  0.04]\n",
      " [-1.6  -0.42]\n",
      " [ 0.98 -1.  ]\n",
      " [ 1.08 -1.21]\n",
      " [-0.01 -0.13]\n",
      " [-1.1  -1.52]\n",
      " [ 0.78 -1.21]\n",
      " [ 0.98  2.07]\n",
      " [-1.2  -1.52]\n",
      " [-0.31  0.79]\n",
      " [ 0.09 -0.31]\n",
      " [-1.4  -1.23]\n",
      " [-0.61 -1.5 ]\n",
      " [ 0.78  0.53]\n",
      " [-0.31 -0.34]\n",
      " [ 1.77 -0.28]\n",
      " [ 0.88 -1.03]\n",
      " [ 0.19  0.07]\n",
      " [-0.61  0.88]\n",
      " [-1.89 -1.41]\n",
      " [-1.3   0.59]\n",
      " [-0.31  0.53]\n",
      " [-1.   -1.09]\n",
      " [ 1.18 -1.44]\n",
      " [ 0.19 -0.31]\n",
      " [ 1.18 -0.74]\n",
      " [-0.31  0.07]\n",
      " [ 0.19  2.1 ]\n",
      " [ 0.78 -1.09]\n",
      " [ 0.09  0.04]\n",
      " [-1.8   0.13]\n",
      " [-0.9   0.16]\n",
      " [-0.71  0.19]\n",
      " [ 0.88 -1.29]\n",
      " [ 0.19 -0.25]\n",
      " [-0.41  1.23]\n",
      " [-0.01  0.3 ]\n",
      " [ 0.38  0.16]\n",
      " [ 0.88 -0.65]\n",
      " [ 0.09  0.16]\n",
      " [-1.89 -1.29]\n",
      " [-0.11  0.3 ]\n",
      " [-0.21 -0.28]\n",
      " [ 0.28 -0.51]\n",
      " [-0.21  1.61]\n",
      " [ 0.98 -1.18]\n",
      " [-0.21  1.64]\n",
      " [ 1.27  1.87]\n",
      " [-1.1  -0.36]\n",
      " [-0.01  0.04]\n",
      " [ 0.09 -0.25]\n",
      " [-1.6  -1.23]\n",
      " [-0.51 -0.28]\n",
      " [ 0.98  0.13]\n",
      " [ 1.97 -1.35]\n",
      " [ 1.47  0.07]\n",
      " [-0.61  1.37]\n",
      " [ 1.57  0.01]\n",
      " [-0.8   0.3 ]\n",
      " [ 1.97  0.74]\n",
      " [-1.2  -0.51]\n",
      " [ 0.68  0.27]\n",
      " [-1.4  -0.42]\n",
      " [ 0.19  0.16]\n",
      " [-0.51 -1.21]\n",
      " [ 0.58  2.01]\n",
      " [-1.6  -1.5 ]\n",
      " [-0.51 -0.54]\n",
      " [ 0.48  1.84]\n",
      " [-1.4  -1.09]\n",
      " [ 0.78 -1.38]\n",
      " [-0.31 -0.42]\n",
      " [ 1.57  1.  ]\n",
      " [ 0.98  1.43]\n",
      " [-0.31 -0.48]\n",
      " [-0.11  2.16]\n",
      " [-1.5  -0.1 ]\n",
      " [-0.11  1.95]\n",
      " [-0.71 -0.34]\n",
      " [-0.51 -0.83]\n",
      " [ 0.68 -1.38]\n",
      " [-0.8  -1.58]\n",
      " [-1.89 -1.47]\n",
      " [ 1.08  0.13]\n",
      " [ 0.09  1.52]\n",
      " [-0.31  0.1 ]\n",
      " [ 0.09  0.04]\n",
      " [-1.4  -1.35]\n",
      " [ 0.28  0.07]\n",
      " [-0.9   0.39]\n",
      " [ 1.57 -1.26]\n",
      " [-0.31 -0.74]\n",
      " [-0.11  0.16]\n",
      " [-0.9  -0.65]\n",
      " [-0.71 -0.05]\n",
      " [ 0.38 -0.45]\n",
      " [-0.8   1.9 ]\n",
      " [ 1.37  1.29]\n",
      " [ 1.18 -0.97]\n",
      " [ 1.77  1.84]\n",
      " [-0.9  -0.25]\n",
      " [-0.8   0.56]\n",
      " [-1.2  -1.55]\n",
      " [-0.51 -1.12]\n",
      " [ 0.28  0.07]\n",
      " [-0.21 -1.06]\n",
      " [ 1.67  1.61]\n",
      " [ 0.98  1.78]\n",
      " [ 0.28  0.04]\n",
      " [-0.8  -0.22]\n",
      " [-0.11  0.07]\n",
      " [ 0.28 -0.19]\n",
      " [ 1.97 -0.65]\n",
      " [-0.8   1.35]\n",
      " [-1.8  -0.6 ]\n",
      " [-0.11  0.13]\n",
      " [ 0.28 -0.31]\n",
      " [ 1.08  0.56]\n",
      " [-1.    0.27]\n",
      " [ 1.47  0.36]\n",
      " [ 0.19 -0.36]\n",
      " [ 2.17 -1.03]\n",
      " [-0.31  1.11]\n",
      " [-1.7   0.07]\n",
      " [-0.01  0.04]\n",
      " [ 0.09  1.06]\n",
      " [-0.11 -0.36]\n",
      " [-1.2   0.07]\n",
      " [-0.31 -1.35]\n",
      " [ 1.57  1.11]\n",
      " [-0.8  -1.52]\n",
      " [ 0.09  1.87]\n",
      " [-0.9  -0.77]\n",
      " [-0.51 -0.77]\n",
      " [-0.31 -0.92]\n",
      " [ 0.28 -0.71]\n",
      " [ 0.28  0.07]\n",
      " [ 0.09  1.87]\n",
      " [-1.1   1.95]\n",
      " [-1.7  -1.55]\n",
      " [-1.2  -1.09]\n",
      " [-0.71 -0.1 ]\n",
      " [ 0.09  0.1 ]\n",
      " [ 0.28  0.27]\n",
      " [ 0.88 -0.57]\n",
      " [ 0.28 -1.15]\n",
      " [-0.11  0.68]\n",
      " [ 2.17 -0.68]\n",
      " [-1.3  -1.38]\n",
      " [-1.   -0.94]\n",
      " [-0.01 -0.42]\n",
      " [-0.21 -0.45]\n",
      " [-1.8  -0.97]\n",
      " [ 1.77  1.  ]\n",
      " [ 0.19 -0.36]\n",
      " [ 0.38  1.11]\n",
      " [-1.8  -1.35]\n",
      " [ 0.19 -0.13]\n",
      " [ 0.88 -1.44]\n",
      " [-1.99  0.48]\n",
      " [-0.31  0.27]\n",
      " [ 1.87 -1.06]\n",
      " [-0.41  0.07]\n",
      " [ 1.08 -0.89]\n",
      " [-1.1  -1.12]\n",
      " [-1.89  0.01]\n",
      " [ 0.09  0.27]\n",
      " [-1.2   0.33]\n",
      " [-1.3   0.3 ]\n",
      " [-1.    0.45]\n",
      " [ 1.67 -0.89]\n",
      " [ 1.18  0.53]\n",
      " [ 1.08  0.53]\n",
      " [ 1.37  2.33]\n",
      " [-0.31 -0.13]\n",
      " [ 0.38 -0.45]\n",
      " [-0.41 -0.77]\n",
      " [-0.11 -0.51]\n",
      " [ 0.98 -1.15]\n",
      " [-0.9  -0.77]\n",
      " [-0.21 -0.51]\n",
      " [-1.1  -0.45]\n",
      " [-1.2   1.4 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8   0.5 ]\n",
      " [-0.01 -0.57]\n",
      " [-0.31  0.16]\n",
      " [-0.8   0.27]\n",
      " [-0.31 -0.57]\n",
      " [-1.1  -1.44]\n",
      " [-0.71 -1.58]\n",
      " [-0.21  2.16]\n",
      " [-1.99 -0.05]\n",
      " [ 0.88 -0.77]\n",
      " [-0.8  -0.6 ]\n",
      " [-1.   -0.42]\n",
      " [-0.11 -0.42]\n",
      " [ 0.09  0.22]\n",
      " [-1.8   0.48]\n",
      " [-0.61  1.37]\n",
      " [-0.11  0.22]\n",
      " [-1.89  0.45]\n",
      " [ 1.67  1.75]\n",
      " [-0.31 -1.38]\n",
      " [-0.31 -0.65]\n",
      " [ 0.88  2.16]\n",
      " [ 0.28 -0.54]\n",
      " [ 0.88  1.03]\n",
      " [-1.5  -1.21]\n",
      " [ 1.08  2.07]\n",
      " [-1.    0.5 ]\n",
      " [-0.9   0.3 ]\n",
      " [-0.11 -0.22]\n",
      " [-0.61  0.48]\n",
      " [-1.7   0.53]\n",
      " [-0.11  0.27]\n",
      " [ 1.87 -0.28]\n",
      " [-0.11 -0.48]\n",
      " [-1.4  -0.34]\n",
      " [-1.99 -0.51]\n",
      " [-1.6   0.33]\n",
      " [-0.41 -0.77]\n",
      " [-0.71 -1.03]\n",
      " [ 1.08 -0.97]\n",
      " [-1.1   0.53]\n",
      " [ 0.28 -0.51]\n",
      " [-1.1   0.42]\n",
      " [-0.31 -1.44]\n",
      " [ 0.48  1.23]\n",
      " [-1.1  -0.34]\n",
      " [-0.11  0.3 ]\n",
      " [ 1.37  0.59]\n",
      " [-1.2  -1.15]\n",
      " [ 1.08  0.48]\n",
      " [ 1.87  1.52]\n",
      " [-0.41 -1.29]\n",
      " [-0.31 -0.36]\n",
      " [-0.41  1.32]\n",
      " [ 2.07  0.53]\n",
      " [ 0.68 -1.09]\n",
      " [-0.9   0.39]\n",
      " [-1.2   0.3 ]\n",
      " [ 1.08 -1.21]\n",
      " [-1.5  -1.44]\n",
      " [-0.61 -1.5 ]\n",
      " [ 2.17 -0.8 ]\n",
      " [-1.89  0.19]\n",
      " [-0.21  0.85]\n",
      " [-1.89 -1.26]\n",
      " [ 2.17  0.39]\n",
      " [-1.4   0.56]\n",
      " [-1.1  -0.34]\n",
      " [ 0.19 -0.65]\n",
      " [ 0.38  0.01]\n",
      " [-0.61  2.33]\n",
      " [-0.31  0.22]\n",
      " [-1.6  -0.19]\n",
      " [ 0.68 -1.38]\n",
      " [-1.1   0.56]\n",
      " [-1.99  0.36]\n",
      " [ 0.38  0.27]\n",
      " [ 0.19 -0.28]\n",
      " [ 1.47 -1.03]\n",
      " [ 0.88  1.08]\n",
      " [ 1.97  2.16]\n",
      " [ 2.07  0.39]\n",
      " [-1.4  -0.42]\n",
      " [-1.2  -1.  ]\n",
      " [ 1.97 -0.92]\n",
      " [ 0.38  0.3 ]\n",
      " [ 0.19  0.16]\n",
      " [ 2.07  1.75]\n",
      " [ 0.78 -0.83]\n",
      " [ 0.28 -0.28]\n",
      " [ 0.38 -0.16]\n",
      " [-0.11  2.22]\n",
      " [-1.5  -0.63]\n",
      " [-1.3  -1.06]\n",
      " [-1.4   0.42]\n",
      " [-1.1   0.77]\n",
      " [-1.5  -0.19]\n",
      " [ 0.98 -1.06]\n",
      " [ 0.98  0.59]\n",
      " [ 0.38  1.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training logistic regression model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "# The parameter C helps prevent overfitting \n",
    "# (higher C is more regularization)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting a new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppose a new customer is aged 30 with\n",
    "# an annual salary of $87000\n",
    "# This is the first value in the testing set\n",
    "\n",
    "# Note that X_test has already been scaled\n",
    "\n",
    "\n",
    "classifier.predict([X_test[0, :]]) # Our classifier predicts 0\n",
    "y_test[0] # The correct answer is 0\n",
    "\n",
    "# Our model correctly predicts that this customer does\n",
    "# not purchase the new car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting testing set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), \n",
    "                      y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  3]\n",
      " [ 8 24]]\n",
      "0.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Will show us the number of correct predictions\n",
    "# and the number of incorrect predictions\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(cm), print(acc_score)\n",
    "\n",
    "# Interpreting the confusion matrix:\n",
    "# 65 correct predictions in class 0, 24 correct predictions of class 1\n",
    "# 3 incorrect predictions in class 0, 8 incorrect predictions of class 1\n",
    "# Accuracy score tells us 89% of predictions were correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing training set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-1f683646bdd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                      np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\n\u001b[1;32m      8\u001b[0m plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n\u001b[0;32m----> 9\u001b[0;31m              alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mcontourf\u001b[0;34m(data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2529\u001b[0m     __ret = gca().contourf(\n\u001b[1;32m   2530\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m   2532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mcontourf\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcontourf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6429\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filled'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6430\u001b[0;31m         \u001b[0mcontours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcontour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQuadContourSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6431\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6432\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/contour.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ax, levels, filled, linewidths, linestyles, alpha, origin, extent, cmap, colors, norm, vmin, vmax, extend, antialiased, *args, **kwargs)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallsegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallkinds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_allsegs_and_allkinds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/contour.py\u001b[0m in \u001b[0;36m_get_allsegs_and_allkinds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1491\u001b[0m                 \u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkinds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                     self._contour_generator.create_filled_contour(\n\u001b[0;32m-> 1493\u001b[0;31m                         level, level_upper)\n\u001b[0m\u001b[1;32m   1494\u001b[0m                 \u001b[0mallsegs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m                 \u001b[0mallkinds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkinds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code is only useful for training purposes\n",
    "# Most likely not used in real-world situations\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = sc.inverse_transform(X_train), y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\n",
    "plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Logistic Regression (Training set)')\n",
    "plt.xlabel('Customer Age')\n",
    "plt.ylabel('Estimated Salary ($)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing testing set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = sc.inverse_transform(X_test), y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\n",
    "plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Logistic Regression (Test set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
