---
title: "9.3 - Kernel Principal Component Analysis"
output: html_notebook
author: Glenn Bucagu
---

Kernel PCA is ideal for non-linearly separable classification problems.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/Desktop/Projects/Machine Learning A-Z (Codes and Datasets)/Part 9 - Dimensionality Reduction/Section 45 - Kernel PCA/R")
```

```{r importing the dataset}
dataset <- read.csv("Social_Network_Ads.csv")[3:5]
dataset
```

```{r splitting the dataset into training and testing set}
library(caTools)
split <- sample.split(dataset$Purchased, SplitRatio = 0.8)
training_set <- subset(dataset, split == TRUE)
test_set <- subset(dataset, split == FALSE)

training_set
test_set

```

```{r feature scaling}
training_set[-3] <- scale(training_set[-3])
test_set[-3] <- scale(test_set[-3])

training_set
test_set
```


```{r applying Kernel PCA to the dataset}
#install.packages("kernlab")
library(kernlab)
kpca <- kpca(~.,
             data = training_set[-3],
             kernel = "rbfdot",
             features = 2)

training_set_pca <- as.data.frame(predict(kpca, training_set))
training_set_pca$Purchased <- training_set$Purchased


test_set_pca <- as.data.frame(predict(kpca, test_set))
test_set_pca$Purchased <- test_set$Purchased
training_set_pca
test_set_pca





```

```{r fit logistic regression to the training set}
library(e1071)
classifier <- svm(formula = Purchased ~ .,
                  data = training_set_pca,
                  type = "C-classification",
                  kernel = "radial")
  

```

```{r making predictions on the test set}
y_pred <- predict(classifier, newdata = test_set_pca[-3],
                  type = "class")
y_pred
```


```{r evaluating the model}
cm <- table(test_set_pca[, 3], y_pred)
cm

```


```{r visualizing training set results}
# install.packages("~/Downloads/ElemStatLearn_2015.6.26.tar", type = "source", repos = NULL)
library(ElemStatLearn)
set = training_set_pca
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c("V1", "V2")
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3], 
     main = "SVM (training set)", 
     xlab = "V1", ylab = "V2", 
     xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = ".", col = ifelse(y_grid == 1, "springgreen3", "tomato"))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, "green4", "red3"))


```



```{r visualizing testing set results}
# install.packages("~/Downloads/ElemStatLearn_2015.6.26.tar", type = "source", repos = NULL)
library(ElemStatLearn)
set = test_set_pca
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c("V1", "V2")
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3], 
     main = "SVM (test set)", 
     xlab = "V1", ylab = "V2", 
     xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = ".", col = ifelse(y_grid == 1, "springgreen3", "tomato"))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, "green4", "red3"))


```