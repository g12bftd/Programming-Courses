{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding neurons:\n",
    "- We have an input layer, hidden layers and finally an output layer\n",
    "- There is a calculation that weights the value of each input\n",
    "- The activation function is applied\n",
    "\n",
    "Activation function examples:\n",
    "Activation functions introduce non-linearity to neural network input data. This is because real life phenomena rarely follow linear behavior. Additionally, each activation function has its own advantages.\n",
    "\n",
    "- Threshold function: 0/1 heaviside function\n",
    "- Sigmoid function : 1 / (1 + e^-x) \n",
    "- Rectifier function : max(x, 0)\n",
    "- Hyperbolic tangent: (1 - e^(-2x)) / (1 + e^(-2x))\n",
    "\n",
    "Threshold & sigmoid functions ideal for output values between 0 and 1.\n",
    "\n",
    "Hyperbolic tangent centres around zero and acts as a normalizer for subsequent layers of the neural network to operate on.\n",
    "\n",
    "How Neural Networks learn - Backpropagation:\n",
    "- Given inputs, weights are applied, activation function is applied and the neural network produces a prediction\n",
    "- Prediction is compared with a true value\n",
    "- Compute some established cost that illustrates how similar the prediction is to the true value\n",
    "- Goal of the neural network is to produce the weights that minimize the cost function.\n",
    "- Cost function example: 1/2 * (y_pred - y_true)^2\n",
    "- Epoch: number of passes the entire training dataset has completed\n",
    "\n",
    "\n",
    "Minimizing the cost function:\n",
    "- In general, this is a convex optimization problem with a unique global minimum\n",
    "- Several algorithms exist to solve this optimization problem\n",
    "- Examples include gradient descent & stochastic gradient descent\n",
    "\n",
    "Gradient Descent algorithm:\n",
    "- Start with some learning rate (hyperparameter) > 0\n",
    "- Start with some input \n",
    "- Loop: compute gradient at current point\n",
    "    - input = input - learning_rate * gradient\n",
    "    - convergence condition (some tolerance reached)\n",
    "\n",
    "Stochastic Gradient Descent algorithm:\n",
    "- Does not require objective function to be convex\n",
    "- Choose initial input parameters and learning rate\n",
    "- Loop:\n",
    "    - randomly shuffle examples in the training set\n",
    "    - compute gradient at a single point \n",
    "    - input = input - learning rate * gradient at point\n",
    "Note: GD is generally quicker than SGD because of the randomized fluctuations we see in SGD\n",
    "\n",
    "Process:\n",
    "1) Randomly initialize the weights to numbers close to 0 but not 0\n",
    "\n",
    "2) Input the first observation of dataset into input layer, each feature in one input node\n",
    "\n",
    "3) Forward propagation - from left to right, neurons are activated such taht the imact of each neuron's activation is limited by the weights. We obtain a predicted result y.\n",
    "\n",
    "4) Compare the predicted result to the true value of y. Compute the cost using the given cost function.\n",
    "\n",
    "5) Backpropagation - from right to left update the weights according to how much they are responsible for the error\n",
    "6) Repeat steps 1-5 after each observation or batch of observations\n",
    "\n",
    "7) When the whole training set is passed, that makes an epoch.\n",
    "\n",
    "In general, the more epochs pass, the more accurate the ANN will be.\n",
    "\n",
    "Business problem:\n",
    "- Given some information about bank customers \n",
    "- We want to minimize the churn rate (rate at which customers are leaving bank).\n",
    "- Dataset contains 10,000 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]] [1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for the \"Gender\" column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])\n",
    "\n",
    "#One-Hot encoding for the \"Geography\" column\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will build the ANN as a sequence of layers instead of\n",
    "# computational graph\n",
    "\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the input and hidden layers to the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a single hidden layer with re-lu activation function\n",
    "# the number of neurons is a sort of hyperparameter to be tuned\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "# Add a second hidden layer with 6 neurons and relu activation function\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model for training\n",
    "# Optimizer - optimizer to perform stochastic gradient descent\n",
    "# loss - determines the loss function \n",
    "# metrics - list of metrics to be evaluated by the model when training & testing\n",
    "ann.compile(optimizer = 'adam', \n",
    "            loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7960: 0s - loss: 0.5108 - accuracy: \n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7960\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.7960\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.7964\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8064\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8094\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8114\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.8117\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4053 - accuracy: 0.8146\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8166\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3870 - accuracy: 0.8267\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8356\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8439\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8489\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8509\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8534\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8539\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8574\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8568\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8576\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8583\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8602\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8596\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8620\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8618\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3412 - accuracy: 0.8611\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8612\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8618\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8622\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8627\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8634\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8640\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8620\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8635\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8630\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8644\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8611\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8643\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8636\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8636: 0s - loss: 0.3259 - accura\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8633\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8619\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8636\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8619\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8610\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8622\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8621\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8612\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8633\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8624\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8629\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8624\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8624\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8626\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8626\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8610\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8622\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8624\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8627\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8629\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8633\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8633\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8619\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8629\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8639\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8622\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8626\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8625\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8633\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8637\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8635\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8624\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8626\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8622\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8626\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8615\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8631\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8636\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8621\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8618\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8643\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8635\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8622\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8612\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8621\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8643\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8622\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8635\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8634\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8634\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8634\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8627\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8637\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8620\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8630\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8611\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc2160bee10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for a single observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our ANN model to predict if the customer with the following informations will leave the bank:\n",
    "- Geography: France\n",
    "- Credit Score: 600\n",
    "- Gender: Male\n",
    "- Age: 40 years old\n",
    "- Tenure: 3 years\n",
    "- Balance: 60000\n",
    "- Number of Products: 2\n",
    "- Does this customer have a credit card? Yes\n",
    "- Is this customer an Active Member: Yes\n",
    "- Estimated Salary: 50000\n",
    "- So, should we say goodbye to that customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions using the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc21d541f10>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAbQElEQVR4nO3deXwV1fnH8c8DYd+tLCFQAcXdn4oWUevSoghuoGLBFRVNq/BzrQtuVFBrZVEpoMYCxo2lKIuIIAIVqSK4oixCRIWwimwurZDk+f1xB35XcklukguZjN+3r/PKzJkzM2f0+uTJmXNnzN0REZFwqVTeHRARkcIUnEVEQkjBWUQkhBScRURCSMFZRCSE0vb2CXZsXKHpIFJIjaanlHcXJITytq+2sh6jJDGnyv6tyny+vUWZs4hICO31zFlEZJ8qyC/vHqSEgrOIREt+Xnn3ICUUnEUkUtwLyrsLKaHgLCLRUqDgLCISPsqcRURCSDcERURCSJmziEj4uGZriIiEkG4IioiEkIY1RERCSDcERURCSJmziEgI6YagiEgIReSGoB4ZKiKR4p6fdCmOmY00sw1m9lmCbX82Mzez/YN1M7MhZpZjZgvNrE1c2x5mtjwoPZK5DgVnEYkWL0i+FO9ZoOPulWbWHDgTWBlX3QloHZRM4Mmg7X5AX+AEoC3Q18waFHdiBWcRiZaCguRLMdx9DrApwabHgDuA+LeudAae85h5QH0zSwfOAma4+yZ33wzMIEHA352Cs4hESwkyZzPLNLP340pmcYc3s/OB1e7+yW6bMoBVceu5Qd2e6oukG4IiEi35O5Ju6u5ZQFay7c2sJnAP0CHR5kSnKKK+SMqcRSRaUjiskcCBQEvgEzP7CmgGfGhmTYhlxM3j2jYD1hRRXyQFZxGJltTeEPz5od0/dfdG7t7C3VsQC7xt3H0dMBm4Mpi10Q7Y6u5rgelABzNrENwI7BDUFUnDGiISLSmc52xmo4HTgf3NLBfo6+4j9tB8KnA2kAP8CFwN4O6bzKw/sCBo18/dE91k/BkFZxGJlhQGZ3e/pJjtLeKWHei1h3YjgZElObeCs4hEipfghmCYKTiLSLTowUciIiEUkWdrKDiLSLQocxYRCSFlziIiIaTMWUQkhPL0sH0RkfBR5iwiEkIacxYRCSFlziIiIaTMWUQkhJQ5i4iEkGZriIiEkBf7kpEKQcFZRKJFY84iIiGk4CwiEkK6ISgiEkL5+eXdg5RQcBaRaNGwhohICCk4i4iEUETGnCuVdwdERFLJCzzpUhwzG2lmG8zss7i6AWa21MwWmtkEM6sft62PmeWY2edmdlZcfcegLsfM7krmOhScRSRaCgqSL8V7Fui4W90M4Eh3/x9gGdAHwMwOB7oDRwT7DDezymZWGRgGdAIOBy4J2hZJwxoiEi0pnK3h7nPMrMVudW/Erc4DugbLnYEx7v4T8KWZ5QBtg2057r4CwMzGBG0XF3VuZc4iEi0lyJzNLNPM3o8rmSU82zXA68FyBrAqbltuULen+iIpcxaRaCnBbA13zwKySnMaM7sHyANe3FmV6BQkToKLHfBWcC7CvQ8PZs6/57Nfg/pMfOGpQtvnf7iQG+96gIz0JgCccdpJXH/NZWU65/bt2+nTfxCLP19O/Xp1GdivDxnpjfl08ef85W9DAHCcG665jDNOO7lM55J9r169umQ9PZAjjjgEd+e6627jx//8h+FDH6FW7Zp8/XUuV1zZm++++768u1px7YMHH5lZD+BcoL37rhPmAs3jmjUD1gTLe6rfIw1rFKHL2Wfy1OAHi2zT5ugjeTl7GC9nDytRYF69dj1X9b6jUP0rU96gbp3avD5uJFd068Lg4SMBOKjVAYwdMYSXs4fx9KAH6ffo38nLi8Y3oX5JHhvcj+nTZ3PkUafR5rgzWbJ0OU8/NYC773mYY9ucwcSJr/Pn264v725WbKm9IViImXUE7gTOd/cf4zZNBrqbWTUzawm0BuYDC4DWZtbSzKoSu2k4ubjzFBuczexQM7vTzIaY2RPB8mGluaiK5vhjjqJe3Tql2vfV6bPofu1NXNSjFw88OoT8JG9SzHr7XTqffQYAHU4/hfc++Bh3p0b16qSlVQbgp+3bwRL9BSVhVqdObU757QmMHDUagB07drB16zYOOfhA5rw9D4A3Z77NBRecXZ7drPgKPPlSDDMbDbwLHGJmuWbWExgK1AFmmNnHZvYUgLsvAsYRu9E3Dejl7vnungf0BqYDS4BxQdsiFRmczexOYAyxsZSdvwEMGJ3sXL2o++SzJVzY4wb+dNt95Kz4GoAvvlrJtJlv8fxTg3g5exiVKlViyhuzkzrehm++pUmj/QFIS6tM7Vo12bJ1GwALFy2l82V/5IIrr+f+23vvCtZSMbRqdQAbN37LiH88xoL503n6qQHUrFmDRYs+57zzOgDQ9aJzad6saTn3tILLz0++FMPdL3H3dHev4u7N3H2Eux/k7s3d/Zig/Cmu/UPufqC7H+Lur8fVT3X3g4NtDyVzGcWNOfcEjnD3HfGVZjYYWAQ8kmin4I5nJsDwQQ9y7ZWXJNOXCufwQw5kxsvZ1KxZgznvzOfGPv2YOnYE773/MYuX5tC9500A/PTTT+zXIDZP/cY+/Vi9Zj078nawdv03XNSjFwCX/6EzF5zTAU8wXmZBlvw/RxzKpBef5ouvVnLPg4M4pd1vqFat6j66WimrtMqVOfbYo7jp5vuYv+AjBg96gDvv6M21mbfy+OD+3HvPLUyZ8gbbt+8o/mCyR/4L+fp2AdAU+Hq3+vRgW0Lxd0B3bFwRjdcSJFC7Vq1dy6ee1JYHBw1j85atuDvndzqDW66/utA+Q/56PxAbc77noUE8O/TRn21v3Gh/1m3YSJNGDcnLy+f7H34sNLRyYItfU6N6dZav+IojDzt4L1yZ7A25q9eSm7uW+Qs+AuCVV17jjtt70/cvA+h0zqUAtG7dirM7tS/PblZ8SQxXVATFjTnfDMw0s9fNLCso04CZwE17v3vhtvHbTbsy3U8Xf06BO/Xr1aXd8ccw419z+XbzFgC2bvuONevWJ3XM3/22HZOmvgnAG/96mxOOOxozI3fNul03ANesW89XK3PJSG+8F65K9pb1678hN3cNBx98IAC///1vWbJkGQ0b/gqI/YV0d5+beDrr+fLsZsXnBcmXECsyc3b3aWZ2MLFvuWQQG2/OBRa4e+SnCtze9xEWfLSQLVu20b7L5dzQ8wrygpdHdrvgHN6YPZexE16jclplqletyoAH7sLMOLDlAfzvdVeSefM9FHgBVdLSuOfWG2japPhgeuG5Z9Gn/wA6/eEa6tWtw4AHYkP7Hy5cxIjnx5GWlkalSsa9f+5Fg/r19ur1S+rddMt9PJf9d6pWrcKXX66k57W3csXlXbn++qsAmDhxKs9mjy3fTlZ0EcmcLdEYZypFeVhDSq9G01PKuwsSQnnbV5d5GtIP93dPOubU6jcmtNOe9CUUEYmWkA9XJEvBWUSiJSLDGgrOIhIpv5SpdCIiFYsyZxGREFJwFhEJoRQ+bL88KTiLSKQk827AikDBWUSiRcFZRCSENFtDRCSElDmLiISQgrOISPh4voY1RETCR5mziEj4aCqdiEgYKTiLiIRQNIaci31NlYhIheJ5BUmX4pjZSDPbYGafxdXtZ2YzzGx58LNBUG9mNsTMcsxsoZm1idunR9B+uZn1SOY6FJxFJFoKSlCK9yzQcbe6u4CZ7t6a2PtU7wrqOwGtg5IJPAmxYA70BU4g9sq/vjsDelEUnEUkUrzAky7FHst9DrBpt+rOQHawnA10iat/zmPmAfXNLB04C5jh7pvcfTMwg8IBvxAFZxGJlhJkzmaWaWbvx5XMJM7Q2N3XAgQ/GwX1GcCquHa5Qd2e6oukG4IiEiklmUrn7llAVopOnehlsV5EfZGUOYtItKR2zDmR9cFwBcHPDUF9LtA8rl0zYE0R9UVScBaRSPG85EspTQZ2zrjoAUyKq78ymLXRDtgaDHtMBzqYWYPgRmCHoK5IGtYQkUjxFM5zNrPRwOnA/maWS2zWxSPAODPrCawELg6aTwXOBnKAH4GrAdx9k5n1BxYE7fq5++43GQtRcBaRaElhcHb3S/awqX2Ctg702sNxRgIjS3JuBWcRiZRUZs7lScFZRCJFwVlEJIQ8P9HMtYpHwVlEIkWZs4hICHmBMmcRkdBR5iwiEkLuypxFREJHmbOISAgVaLaGiEj46IagiEgIKTiLiISQR+Pl2wrOIhItypxFREJIU+lEREIoX7M1RETCR5mziEgIacxZRCSENFtDRCSElDmLiIRQfkGl8u5CSig4i0ikRGVYIxq/YkREAgVuSZfimNktZrbIzD4zs9FmVt3MWprZe2a23MzGmlnVoG21YD0n2N6iLNeh4CwikeJuSZeimFkGcCNwvLsfCVQGugN/Ax5z99bAZqBnsEtPYLO7HwQ8FrQrNQVnEYkU9+RLEtKAGmaWBtQE1gK/B8YH27OBLsFy52CdYHt7Myv13cm9PuZ8+GEX7+1TSAX067qNyrsLElHJDFfsZGaZQGZcVZa7ZwG4+2ozGwisBP4DvAF8AGxx97ygfS6QESxnAKuCffPMbCvwK2Bjaa5DNwRFJFJKMlsjCMRZibaZWQNi2XBLYAvwT6BTosPs3KWIbSWmYQ0RiRQvQSnGGcCX7v6Nu+8AXgFOAuoHwxwAzYA1wXIu0Bwg2F4P2FTa61BwFpFISeFsjZVAOzOrGYwdtwcWA7OBrkGbHsCkYHlysE6wfZZ76Sf2aVhDRCIlVQ8+cvf3zGw88CGQB3xEbAjkNWCMmT0Y1I0IdhkBPG9mOcQy5u5lOb+Cs4hESipfvu3ufYG+u1WvANomaPtfIGUzIBScRSRSPOF9uYpHwVlEIiVPz3MWEQkfZc4iIiGUyjHn8qTgLCKRosxZRCSElDmLiIRQvjJnEZHwichbqhScRSRaCpQ5i4iET0TeUqXgLCLRohuCIiIhVFD6l4+EioKziERKfnl3IEUUnEUkUjRbQ0QkhDRbQ0QkhDRbQ0QkhDSsISISQppKJyISQvnKnEVEwicqmXOl8u6AiEgqFZSgFMfM6pvZeDNbamZLzOxEM9vPzGaY2fLgZ4OgrZnZEDPLMbOFZtamLNeh4CwikeKWfEnCE8A0dz8UOBpYAtwFzHT31sDMYB2gE9A6KJnAk2W5DgVnEYmUVGXOZlYXOBUYAeDu2919C9AZyA6aZQNdguXOwHMeMw+ob2bppb0OBWcRiZT8EpRitAK+AUaZ2Udm9g8zqwU0dve1AMHPRkH7DGBV3P65QV2pKDiLSKQUWPLFzDLN7P24khl3qDSgDfCkux8L/MD/D2EkkmigpNTfidFsDRGJlJLM1nD3LCBrD5tzgVx3fy9YH08sOK83s3R3XxsMW2yIa988bv9mwJoSdOdnlDmLSKSkaszZ3dcBq8zskKCqPbAYmAz0COp6AJOC5cnAlcGsjXbA1p3DH6WhzFlEIiXFz9b4X+BFM6sKrACuJpbUjjOznsBK4OKg7VTgbCAH+DFoW2oKziISKal8toa7fwwcn2BT+wRtHeiVqnMrOItIpOhh+yIiIVQQkYeGKjiLSKRE5dkaCs4iEinRyJsVnEUkYpQ5i4iEUJ5FI3dWcBaRSIlGaFZwFpGI0bCGiEgIaSqdiEgIRSM0KziLSMRoWENEJITyI5I7KziLSKQocxYRCSFX5iwiEj5RyZz1JpQ9aNK0Mc9PeJpp/x7P1LfH0SPzkkJtWh3UgnFTR7Eo91163nBFSs5btWoVHn/mr7w5fyLjp2WT0Tz28t6TTzuBCW++wJS3xjLhzRdo99vfpOR8UnbpTRvz4sQs3njnZabNHc9VCT4rJXVht/OYNX8Ss+ZP4sJu5wFQvUZ1Rowewox3X2Ha3PHccd+NZT5PFBXgSZcwU3Deg/z8fP7a9zE6ntyViztexWXXXMxBB7f8WZstW7bS/+4B/GP48yU+fkbzdF6Y+HSh+q6XdWHblm2c0bYLo556kdvvj/0PuHnTFv542c2ce1o37ujdlwHD+5XuwiTl8vLzefj+wXQ46SIu6nglV/TsxkEHt0pq35cmPbPrF/BO9erX5cbbM7mgwxV0OfNybrw9k7r16gDwzLDnOPPECznvd905ru3RnNb+5JRfT0XnJShhpuC8B9+s38jihUsB+OGHH/li2Zc0Tm/0szabNm7m048Xk7cjr9D+53ftxPjp2Uye/RL9B95NpUrJ/as+o9NpvDJ2CgDTXp3Jiae0BWDxp5+zYf1GAJYv/YJq1apStWqVUl+fpM436zeyaOdn5fsfyVn2JU3SG/LrFs0YNXYok2a+yNhXR9DqoBZJHe/U35/E3LfmsXXLNrZt/Y65b83jtPYn89///Jd5c98HYMeOPD5buJQmTRsVc7Rfnjw86RJmCs5JyGiezuFHHconH3yWVPsDW7fgnC4d6H5OT87/3aXk5xdwftdOSe3buElD1q1eD8Sy9++3fU+D/er/rE3H89qz+NPP2b59R8kuRPa6jObpHHHUIXz8wWc8PPheHujzKJ3bX8bDfR+j34A+SR2jcXpD1gafAYB1azbQOL3hz9rUqVub9medyjtz5qe0/1HgJfgnzEp9Q9DMrnb3UXvYlglkAjSs/WvqVd+/tKcpdzVr1WDoqAE8dO9Avv/+h6T2OfHUthxx9GG8MuM5AKpVr8a3GzcBMOzZgTQ/oClVqlQhvVkTJs9+CYDsrNG8PPpVzAq/AC32arKYgw5pxe333cjVf0jZq8okRWrWqsHwZwfS/56BFHgBbX5zNENHPLpre9Vqsb90ul5yPldlXgrAAS2bM3LMUHZs38Gqlau5vsdte/gM/P9y5cqVeSLrEbKfGc2qr1fv3YuqgKJyQ7AsszUeABIGZ3fPArIAWjc8Lty/noqQlpbG0FEDmDz+dd54bXbS+5kZE8ZOYdCDQwtt63XVn4FYhvW3v/+Fy7v88Wfb163dQJOMxqxbu4HKlStTu25ttmzeCkCT9EYMzx7I7b3vZ+VXuWW4Mkm1tLQ0ho8ayOTxrzP9tVnUrl2Lbdu+49zfdS/UdvzoyYwfPRmIjTnf3vt+Vq9au2v7ujUbOOHk43atN2naiPf+/cGu9YcH38tXK1Yy6umX9uIVVVxhz4iTVeSwhpkt3EP5FGi8j/pYbh5+/D6+WPYlo556sUT7vTtnPh3Pa89++zcAYjd4mjZrktS+M6e9xYXdzgViwxfz5i4AYn/GZr30BIMeHMqH8z8pUX9k73vkib58sexLRjz5AgDff/8Dq75eQ6fzz9jV5tAjDk7qWHNmvcMpp59I3Xp1qFuvDqecfiJzZr0DwK19bqBO3Tr0v2dA6i8iIgpKUJJhZpXN7CMzmxKstzSz98xsuZmNNbOqQX21YD0n2N6iLNdRXObcGDgL2Lx7f4F3ynLisDvuhGO4oNu5LF20fNfQw6CHhtE0IxZkR2e/zP6NfsWEGc9Tu04tCgqcq/54CZ1OvpicZV/y2F+H8+w/h2FWiby8PB648xHW5K4r9rz/fHESA4f35835E9myeSu3ZN4NwBXXduOAls3pddu19LrtWgCuurgXmzbu/p9G9rXjTziGC7udy9JFy5gyewwAAx8ayi1/upv+A+6m963XkVYljSkTprN00bJij7d1yzaGDnqGiTNigf7vA7PYumUbTdIb0fu268hZtoJXZ40G4LkRYxn3woS9d3EVUL6nPHO+CVgC1A3W/wY85u5jzOwpoCfwZPBzs7sfZGbdg3bdSntS8yIuxMxGAKPcfW6CbS+5+6XFnaAiD2vI3pPvURkZlFRasfGjwgPuJXTpARckHXNe+npCkeczs2ZANvAQcCtwHvAN0MTd88zsROAv7n6WmU0Plt81szRgHdDQiwqyRSgyc3b3nkVsKzYwi4jsayUZc46fvBDICu6Z7fQ4cAdQJ1j/FbDF3XfOn80FMoLlDGAVQBC4twbtN5b0GkBf3xaRiCnJ32Txkxd2Z2bnAhvc/QMzO31ndaLDJLGtxBScRSRSUvi17JOB883sbKA6sTHnx4H6ZpYWZM/NgDVB+1ygOZAbDGvUAzaV9uT6EoqIREqqvoTi7n3cvZm7twC6A7Pc/TJgNtA1aNYDmBQsTw7WCbbPKu14MyhzFpGI2QuzNXZ3JzDGzB4EPgJGBPUjgOfNLIdYxlx4knsJKDiLSKTsjafNufu/gH8FyyuAtgna/Be4OFXnVHAWkUiJyiRNBWcRiZSofH1bwVlEIiXsD9FPloKziERKGSZIhIqCs4hESr4yZxGR8NGwhohICGlYQ0QkhJQ5i4iEkKbSiYiE0D74+vY+oeAsIpGiYQ0RkRBScBYRCSHN1hARCSFlziIiIaTZGiIiIRSVN7srOItIpGjMWUQkhDTmLCISQhpzFhEJoQINa4iIhE9UMudK5d0BEZFUyveCpEtRzKy5mc02syVmtsjMbgrq9zOzGWa2PPjZIKg3MxtiZjlmttDM2pTlOhScRSRSCtyTLsXIA25z98OAdkAvMzscuAuY6e6tgZnBOkAnoHVQMoEny3IdCs4iEilegn+KPI77Wnf/MFj+DlgCZACdgeygWTbQJVjuDDznMfOA+maWXtrrUHAWkUgpSeZsZplm9n5cyUx0TDNrARwLvAc0dve1EAvgQKOgWQawKm633KCuVHRDUEQipSQ3BN09C8gqqo2Z1QZeBm52921mtsemCbtTSgrOIhIp+Z6fsmOZWRVigflFd38lqF5vZunuvjYYttgQ1OcCzeN2bwasKe25NawhIpHi7kmXolgsRR4BLHH3wXGbJgM9guUewKS4+iuDWRvtgK07hz9KQ5mziERKCr++fTJwBfCpmX0c1N0NPAKMM7OewErg4mDbVOBsIAf4Ebi6LCdXcBaRSEnVg4/cfS6Jx5EB2ido70CvlJwcBWcRiRh9fVtEJISi8vVtBWcRiRQ9bF9EJIT0sH0RkRDSmLOISAgpcxYRCSG9pkpEJISUOYuIhJBma4iIhJBuCIqIhJCGNUREQkjfEBQRCSFlziIiIRSVMWeLym+ZisDMMoPX4ojsos+FJKI3oexbCV8eKb94+lxIIQrOIiIhpOAsIhJCCs77lsYVJRF9LqQQ3RAUEQkhZc4iIiGk4CwiEkIKzvuImXU0s8/NLMfM7irv/kj5M7ORZrbBzD4r775I+Cg47wNmVhkYBnQCDgcuMbPDy7dXEgLPAh3LuxMSTgrO+0ZbIMfdV7j7dmAM0Lmc+yTlzN3nAJvKux8STgrO+0YGsCpuPTeoExFJSMF537AEdZrDKCJ7pOC8b+QCzePWmwFryqkvIlIBKDjvGwuA1mbW0syqAt2ByeXcJxEJMQXnfcDd84DewHRgCTDO3ReVb6+kvJnZaOBd4BAzyzWznuXdJwkPfX1bRCSElDmLiISQgrOISAgpOIuIhJCCs4hICCk4i4iEkIKziEgIKTiLiITQ/wFAEAsR739SEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1595\n",
      "           1       0.74      0.48      0.59       405\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.81      0.72      0.75      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
